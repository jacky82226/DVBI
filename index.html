<!DOCTYPE html>
<html lang="zh-Hant">
	<head>
		<meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Drone-View Building Idetntification</title>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js">
		<!--<script src="http://code.jquery.com/jquery-1.9.1.js"></script>-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
		<script src="magic.js"></script>
		<link rel="stylesheet" href="styles.css">
	</head>

	<body>
		<div id="header">
		<h2>Drone-View Building Identification by Cross-View Visual Learning and Relative Spatial Estimation</h2>
		</div>
		<div id="container">
			<div id ="main">
			<img width=540 src="first.png" />
			<ul>
				<li>Authors</li>
				<a href="http://www.cmlab.csie.ntu.edu.tw/~jacky82226/">Chun-Wei Chen</a>, <a href ="http://www.cmlab.csie.ntu.edu.tw/~kuonini/">Yin-Hsi Kuo</a>, Tang Lee, Cheng-Han Lee, <a href="http://winstonhsu.info/">Winston Hsu</a>
		        <li>Abstract</li>
		        <p class="content">
Drones become popular recently and equip more sensors than traditional cameras, which bring emerging applications and research. To enable drone-based applications, providing related information (e.g., building) to understand the environment around the drone is essential. We frame this drone-view building identification as building retrieval problem: given a building (multimodal query) with its images, geolocation and drone's current location, we aim to retrieve the most likely proposal (building candidate) on a drone-view image. Despite few annotated drone-view images to date, there are many images of other views from the Web, like ground-level, street-view and aerial images. Thus, we propose a cross-view triplet neural network to learn visual similarity between drone-view and other views, further design relative spatial estimation of each proposal and the drone, and collect new drone-view datasets for the task. Our method outperforms triplet neural network by 0.12 mAP. (i.e., 22.9 to 35.0, +53% in a sub-dataset [LA])
				</p>
				<li>Publication</li>
				Chun-Wei Chen, Yin-Hsi Kuo, Tang Lee, Chen-Han Lee, Winston Hsu. Drone-View Building Identification by Cross-View Visual Learning and Relative Spatial Estimation, CVPR 2018 Workshop 
		        <li>Dataset
		        	<ol>
		        		<li>Drone-BR</li>
		        		<li>Drone-BD</li>
		        		<li>IG-City8</li>
		        	</ol>
		        </li>
		        <li>Experimental Results
		        </li>
		        <li>
		        	Acknowledgement
		        </li>
		        This work was supported in part by MediaTek Inc and the Ministry of Science and Technology, Taiwan, under Grant MOST 107-2634-F-002-007. We also benefit from the grants from NVIDIA and the NVIDIA DGX-1 AI Supercomputer.
    		</ul>
    		</div>
    	</div>
	</body>
</html>